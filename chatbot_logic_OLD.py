import sqlite3
import os
from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# Load environment variables
base_dir = os.path.dirname(os.path.abspath(__file__))
dotenv_path = os.path.join(base_dir, '.env')

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("CRITICAL ERROR: GOOGLE_API_KEY not found in .env file.")
genai.configure(api_key=api_key)
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings)
DATABASE = 'products.db'

# --- THIS IS THE NEW, DYNAMIC BESTSELLER FUNCTION ---
def find_bestsellers():
    """
    Queries the database for the top 3 products based on rating and number of ratings.
    """
    conn = sqlite3.connect(DATABASE)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    # Find products with the highest rating, and use num_ratings as a tie-breaker
    bestsellers = cursor.execute("""
        SELECT * FROM products 
        WHERE num_ratings > 0
        ORDER BY rating DESC, num_ratings DESC 
        LIMIT 3
    """).fetchall()
    conn.close()
    return bestsellers
# --- END OF NEW FUNCTION ---

# --- THIS IS THE NEW, SMARTER, AND DEFINITIVE SEARCH FUNCTION ---
def find_relevant_products(search_term):
    """
    Searches the SQLite database with an intelligent scoring system that
    heavily prioritizes matches in the product's name and brand.
    """
    conn = sqlite3.connect(DATABASE)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    search_words = search_term.lower().split()
    if not search_words:
        return []

    # --- 1. Build the Dynamic Scoring Query ---
    # A match in the name is worth 10 points. A match in the brand is worth 5.
    # A match in the description is only worth 1, acting as a tie-breaker.
    score_clauses = []
    where_clauses = []
    params = []
    
    for word in search_words:
        param = f"%{word}%"
        # Scoring clauses
        score_clauses.append("(CASE WHEN name LIKE ? THEN 10 ELSE 0 END)")
        score_clauses.append("(CASE WHEN brand LIKE ? THEN 5 ELSE 0 END)")
        score_clauses.append("(CASE WHEN description LIKE ? THEN 1 ELSE 0 END)")
        params.extend([param, param, param])
        
        # WHERE clauses - a product is only considered a match if the keyword is in its name or brand.
        where_clauses.append("(name LIKE ? OR brand LIKE ?)")
        params.extend([param, param])

    relevance_score_sql = " + ".join(score_clauses)
    where_sql = " OR ".join(where_clauses)
    
    query = f"""
        SELECT *, ({relevance_score_sql}) as relevance_score
        FROM products
        WHERE ({where_sql})
        ORDER BY relevance_score DESC, rating DESC
        LIMIT 5
    """

    # --- 2. Execute the Query ---
    try:
        products = cursor.execute(query, params).fetchall()
    except Exception as e:
        print(f"Error during smart search: {e}")
        products = []
    
    conn.close()
    return products
# --- END OF NEW FUNCTION ---


# --- THIS IS THE NEW, SMARTER LOGIC ---
def extract_product_entity(user_query, chat_history):
    """
    Step 1: A quick, hidden call to the AI to understand the user's intent.
    """
    if not chat_history:
        return user_query # If there's no history, the entity is just the query itself.

    history_string = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in chat_history])
    
    prompt = f"""
    Based on the following conversation history and the new user question, what is the primary product being discussed?
    Respond with ONLY the key product search terms (e.g., "denim jacket", "black t-shirt") and nothing else.
    If the new question is introducing a completely new topic, just respond with the new question itself.
    If the new question is a generic greeting or unrelated, respond with "NONE".

    HISTORY:
    {history_string}

    NEW USER QUESTION: {user_query}

    SEARCH TERMS:
    """
    try:
        response = model.generate_content(prompt)
        # Clean up the AI's response to be safe for searching
        entity = response.text.strip().replace("\n", "").replace("*", "")
        print(f"AI extracted entity: '{entity}'") # For debugging
        return entity if entity else "NONE"
    except Exception as e:
        print(f"Error during entity extraction: {e}")
        return user_query # Fallback to the original query on error

# Code Generated by Sidekick is for learning and experimentation purposes only.
def get_rag_response(user_query, chat_history):
    response_payload = {"text": "", "products": []}
    
    # --- THIS IS THE KEY FIX ---
    # Step 1: Check for special commands like "bestsellers" FIRST.
    if "bestseller" in user_query.lower():
        retrieved_products = find_bestsellers()
        db_context = "The bestsellers were found in the database."
        # We skip the AI for the text part and create a direct, accurate response.
        response_payload["text"] = "Of course! Here are our current top-selling products that customers are loving:"
    
    # Check for "return policy"
    elif "return policy" in user_query.lower():
        retrieved_products = [] # No products to show for this query
        # Provide the direct, static answer
        response_payload["text"] = "We have a 30-day return policy. You can return any unworn, unwashed, or defective merchandise within 30 days. To start a return, just go to your 'My Orders' page."
        
    else:
        # If it's not a special command, proceed with the normal RAG workflow.
        search_term = extract_product_entity(user_query, chat_history)
        retrieved_products = []
        if search_term.upper() != "NONE":
            retrieved_products = find_relevant_products(search_term)

        db_context = "No products were found in the database matching the search term."
        if retrieved_products:
            db_context = "Relevant information from our database:\n"
            for p in retrieved_products:
                sale_price = p['original_price'] * (1 - p['discount_percent'] / 100.0)
                db_context += f"- Product: {p['name']}, Price: ₹{sale_price:.0f}\n"

        history_string = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in chat_history])
        
        # This is a simplified, direct prompt for the AI's main job
        prompt = f"""You are "Aura Assistant," a friendly and helpful shopping assistant. Based on the provided context and conversation history, answer the user's question concisely.

        CONTEXT: {db_context}
        HISTORY: {history_string}
        USER QUESTION: {user_query}
        YOUR RESPONSE:"""
        
        try:
            ai_response = model.generate_content(prompt)
            response_payload["text"] = ai_response.text
        except Exception as e:
            print(f"Error during AI response generation: {e}")
            response_payload["text"] = "I'm sorry, I'm having a little trouble connecting right now."
    # --- END OF KEY FIX ---

    # After getting the text, add the rich product cards.
    if retrieved_products:
        for product in retrieved_products:
            sale_price = product['original_price'] * (1 - product['discount_percent'] / 100.0)
            response_payload["products"].append({
                "id": product['id'],
                "name": product['name'],
                "image_url": product['image_url'],
                "sale_price": f"₹{sale_price:.0f}"
            })

    return response_payload